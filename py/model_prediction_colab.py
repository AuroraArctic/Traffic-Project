# -*- coding: utf-8 -*-
"""model_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X81EswryaEtK3Om_R7gcb8Yw6hqhSPeW
"""

# Mounting Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Libraries
import pandas as pd
import numpy as np
import math
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from datetime import datetime, timedelta

df = pd.read_csv("/content/drive/MyDrive/First Year/Big Data Technologies/Traffic Project/db/2021-06-10.csv")

df.date = pd.to_datetime(df.date)

# Function to map the counter to a list of previous counters
def timeseriesToSupervised(data,n,h):
    x,y = [],[]
    for i in range(len(data)-n-h+1):
        x.append(data.iloc[i:(i+n),[0,1,3]])
        y.append(data.iloc[i+h+n-1,2])
    return np.array(x),np.array(y)

# Codify datetime or string columns to ordinal or categorical index
def codify(df,column_name):
  df[column_name]= pd.Categorical(df[column_name])
  return df[column_name].cat.codes

# New codified data
df_new = pd.DataFrame()
df_new["time"] = codify(df,"time")
df_new["date"] = codify(df,"date")
df_new["count"] = df["count"]
df_new["station"] = codify(df,"station")

# Train test split (taking the most recent data for testing)
train = df_new.iloc[:-200]
test= df_new.iloc[-200:]

#
trainX,trainy = timeseriesToSupervised(train,n,h)
testX,testy = timeseriesToSupervised(test,n,h)

trainy = trainy.astype("float32")
trainX = trainX.astype("float32")
testy = testy.astype("float32")
testX = testX.astype("float32")

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(trainX.reshape(-1, trainX.shape[-1])).reshape(trainX.shape)
X_test = scaler.transform(testX.reshape(-1, testX.shape[-1])).reshape(testX.shape)

# create and fit the LSTM network
model = Sequential()
model.add(LSTM(1))
model.add(Dense(1,activation="relu"))
model.compile(loss='mean_absolute_error', optimizer='adam')
model.fit(X_train, trainy, epochs=2, batch_size=5, verbose=2)

predictions = model.predict(X_test)

predictions

[int(x) for x in predictions] == testy

# SECOND MODEL
import tensorflow as tf
from keras import Sequential
from keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Activation

input_shape = (15542, 1, 3)
model = Sequential()
model.add(Conv1D(filters = 16, kernel_size=3, activation = "relu"))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(10,activation='relu'))
model.add(Dense(1))
model.compile(loss="mse",optimizer="adam")
history = model.fit(trainX, trainy, epochs=1,verbose=1)
predictions_2 = model.predict(testX)

# univariate stacked lstm example
from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense

# split a univariate sequence
def split_sequence(sequence, n_steps):
	X, y = list(), list()
	for i in range(len(sequence)):
		# find the end of this pattern
		end_ix = i + n_steps
		# check if we are beyond the sequence
		if end_ix > len(sequence)-1:
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
		X.append(seq_x)
		y.append(seq_y)
	return array(X), array(y)

# define input sequence
raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]
# choose a number of time steps
n_steps = 3
n_features = 1

es = df[df['station']=='Torricelli']

raw_seq = array(df[['count']])

raw_seq

# split into samples
X, y = split_sequence(raw_seq, n_steps)
# reshape from [samples, timesteps] into [samples, timesteps, features]
X = X.reshape((X.shape[0], X.shape[1], n_features))

X

# define model
model = Sequential()
model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))
model.add(LSTM(50, activation='relu'))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
# fit model
model.fit(X, y, epochs=200, verbose=0)

# demonstrate prediction
x_input = array([40,50,60])
x_input = x_input.reshape((1, n_steps, n_features))
yhat = model.predict(x_input, verbose=0)
print(yhat)

es[es['time'].str.startswith("08:")]

df